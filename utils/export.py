# -*- coding: utf-8 -*-
"""
–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç semantic_db/serializer.py, –∫–æ—Ç–æ—Ä—ã–π —Ñ–æ–∫—É—Å–∏—Ä—É–µ—Ç—Å—è –Ω–∞ –º–∞—à–∏–Ω–Ω–æ–π –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏, UniversalExporter –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –Ω–∞ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫—É—é —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å:

- –≠–∫—Å–ø–æ—Ä—Ç –≤ –≥—Ä–∞—Ñ–æ–≤—ã–µ –±–∞–∑—ã (GraphML ‚Üí Neo4j, Gephi);
- –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Å–µ—Ç–µ–π (RDF/Turtle ‚Üí Apache Jena, Stardog);
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–æ–≤ –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞ (Markdown, PDF —á–µ—Ä–µ–∑ LaTeX);
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º—É–ª—å—Ç–∏–º–µ–¥–∏–π–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π (–¥–ª—è —Ö—É–¥–æ–∂–Ω–∏–∫–æ–≤ –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–π).

¬´–≠–∫—Å–ø–æ—Ä—Ç ‚Äî —ç—Ç–æ –Ω–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ, –∞ –ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —è–∑—ã–∫ –¥—Ä—É–≥–æ–π —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏.¬ª
‚Äî Œõ-–£–Ω–∏–≤–µ—Ä—Å—É–º, –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ XIX

–£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –≠–ö–°–ü–û–†–¢–Å–†

–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã LOGOS-Œ∫ –≤ —Ñ–æ—Ä–º–∞—Ç—ã,
—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–µ —Å –≤–Ω–µ—à–Ω–∏–º–∏ —ç–∫–æ—Å–∏—Å—Ç–µ–º–∞–º–∏:
- –ì—Ä–∞—Ñ–æ–≤—ã–µ –±–∞–∑—ã (GraphML, GML)
- –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Å–µ—Ç–∏ (RDF, Turtle)
- –ß–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º—ã–µ –æ—Ç—á—ë—Ç—ã (Markdown, LaTeX)
- –ú—É–ª—å—Ç–∏–º–µ–¥–∏–π–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è (JSON –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏)

¬´–≠–∫—Å–ø–æ—Ä—Ç ‚Äî —ç—Ç–æ –Ω–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ, –∞ –ø–µ—Ä–µ–≤–æ–¥ –Ω–∞ —è–∑—ã–∫ –¥—Ä—É–≥–æ–π —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏.¬ª
‚Äî Œõ-–£–Ω–∏–≤–µ—Ä—Å—É–º, –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ XIX
"""
import json
import yaml
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime


class UniversalExporter:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤.
    """

    def __init__(self, context):
        self.context = context

    def export_to(self,
                  format_type: str,
                  output_path: str,
                  metadata: Optional[Dict[str, Any]] = None) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã:
        - graphml, gml        ‚Üí –≥—Ä–∞—Ñ–æ–≤—ã–µ –±–∞–∑—ã
        - rdf, turtle         ‚Üí —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Å–µ—Ç–∏
        - markdown, latex     ‚Üí —á–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º—ã–µ –æ—Ç—á—ë—Ç—ã
        - json_viz            ‚Üí –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤–µ–±-–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
        """
        path = Path(output_path)
        path.parent.mkdir(parents=True, exist_ok=True)

        if format_type == "graphml":
            return self._export_graphml(path)
        elif format_type == "gml":
            return self._export_gml(path)
        elif format_type in ("rdf", "turtle"):
            return self._export_turtle(path)
        elif format_type == "markdown":
            return self._export_markdown(path, metadata)
        elif format_type == "latex":
            return self._export_latex(path, metadata)
        elif format_type == "json_viz":
            return self._export_json_viz(path)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞: {format_type}")

    def _export_graphml(self, path: Path) -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ GraphML –¥–ª—è Gephi, yEd –∏ –¥—Ä."""
        from semantic_db.serializer import SemanticDBSerializer
        serializer = SemanticDBSerializer(self.context)
        serializer.export_cycle({'cycle_id': 'graphml_export'}, str(path))
        return str(path)

    def _export_gml(self, path: Path) -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ GML (Graph Modelling Language)."""
        import networkx as nx
        nx.write_gml(self.context.graph, str(path))
        return str(path)

    def _export_turtle(self, path: Path) -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ Turtle (RDF) –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Å–µ—Ç–µ–π."""
        from semantic_db.serializer import SemanticDBSerializer
        serializer = SemanticDBSerializer(self.context)
        ttl_content = serializer.to_turtle({'cycle_id': 'turtle_export'})
        path.write_text(ttl_content, encoding='utf-8')
        return str(path)

    def _export_markdown(self, path: Path, metadata: Optional[Dict] = None) -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ —á–µ–ª–æ–≤–µ–∫–æ-—á–∏—Ç–∞–µ–º—ã–π Markdown-–æ—Ç—á—ë—Ç."""
        summary = self.context.get_summary()
        events = self.context.event_history[-10:]
        tensions = self.context.tension_log

        md = f"""# –û–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –æ—Ç—á—ë—Ç: {self.context.name}

> –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ LOGOS-Œ∫ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å Œõ-–ü—Ä–æ—Ç–æ–∫–æ–ª–æ–º 6.0  
> –î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## üìä –°–≤–æ–¥–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è

- **–°—É—â–Ω–æ—Å—Ç–∏**: {summary['graph_metrics']['nodes']}
- **–°–≤—è–∑–∏**: {summary['graph_metrics']['edges']}
- **–ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å**: {summary['current_coherence']:.2%}
- **–¢—Ä–µ–Ω–¥**: {summary['recent_activity']['coherence_trend']}
- **–ù–∞–ø—Ä—è–∂–µ–Ω–∏—è**: {len(tensions)}
- **Œ¶-–¥–∏–∞–ª–æ–≥–æ–≤**: {summary['ontological_health']['phi_dialogues']}
- **–°–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞**: {', '.join(summary['blinds_spots'].keys())}

## üî• –ê–∫—Ç–∏–≤–Ω—ã–µ –Ω–∞–ø—Ä—è–∂–µ–Ω–∏—è

{"–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –Ω–∞–ø—Ä—è–∂–µ–Ω–∏–π." if not tensions else ""}
{chr(10).join(f"- {t}" for t in tensions[:5]) if tensions else ""}

## üß™ –ü–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è

{chr(10).join(f"- **{e.gesture}**: {e.operands} ‚Üí {e.result} (–∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å: {e.coherence_after:.2%})" for e in events)}

## üåå –°–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞

{chr(10).join(f"- **{k}**: {v}" for k, v in summary['blinds_spots'].items())}

---
*–≠—Ç–æ—Ç –æ—Ç—á—ë—Ç ‚Äî –∂–∏–≤–æ–π –∞—Ä—Ç–µ—Ñ–∞–∫—Ç Œõ-–£–Ω–∏–≤–µ—Ä—Å—É–º–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é.*
"""
        path.write_text(md, encoding='utf-8')
        return str(path)

    def _export_latex(self, path: Path, metadata: Optional[Dict] = None) -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ LaTeX –¥–ª—è –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö –ø—É–±–ª–∏–∫–∞—Ü–∏–π."""
        summary = self.context.get_summary()
        tex = rf"""\documentclass{{article}}
\usepackage[utf8]{{inputenc}}
\usepackage[russian]{{babel}}
\usepackage{{geometry}}
\geometry{{a4paper, margin=2cm}}
\title{{–û–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –æ—Ç—á—ë—Ç: {self.context.name}}}
\author{{LOGOS-$\kappa$}}
\date{{\today}}

\begin{{document}}
\maketitle

\section*{{–°–≤–æ–¥–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è}}
\begin{{itemize}}
    \item –°—É—â–Ω–æ—Å—Ç–∏: {summary['graph_metrics']['nodes']}
    \item –°–≤—è–∑–∏: {summary['graph_metrics']['edges']}
    \item –ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å: {summary['current_coherence']:.2\%}
    \item –¢—Ä–µ–Ω–¥: {summary['recent_activity']['coherence_trend']}
    \item –ù–∞–ø—Ä—è–∂–µ–Ω–∏—è: {len(self.context.tension_log)}
    \item $\Phi$-–¥–∏–∞–ª–æ–≥–æ–≤: {summary['ontological_health']['phi_dialogues']}
\end{{itemize}}

\section*{{–°–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞}}
\begin{{itemize}}
{'\n'.join(f"    \\item \\textbf{{{k}}}: {v}" for k, v in summary['blinds_spots'].items())}
\end{{itemize}}

\end{{document}}
"""
        path.write_text(tex, encoding='utf-8')
        return str(path)

    def _export_json_viz(self, path: Path) -> str:
        """–≠–∫—Å–ø–æ—Ä—Ç –≤ JSON –¥–ª—è –≤–µ–±-–≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ (D3.js, Sigma.js)."""
        nodes = []
        for node, attrs in self.context.graph.nodes(data=True):
            nodes.append({
                "id": node,
                "label": node,
                "type": attrs.get('type', 'entity'),
                "is_blind_spot": node in self.context.blind_spots,
                "size": self.context.graph.degree(node) + 5
            })

        edges = []
        for source, target, attrs in self.context.graph.edges(data=True):
            rel = attrs.get('relation')
            edges.append({
                "from": source,
                "to": target,
                "type": rel.type if rel else "connection",
                "certainty": rel.certainty if rel else 1.0,
                "tension": rel.tension_level if rel else 0.0,
                "color": "#ff0000" if rel and rel.tension_level > 0.7 else "#888888"
            })

        viz_data = {
            "nodes": nodes,
            "edges": edges,
            "metadata": {
                "context_name": self.context.name,
                "generated_at": datetime.now().isoformat(),
                "coherence": self.context._dynamic_coherence()
            }
        }

        path.write_text(json.dumps(viz_data, ensure_ascii=False, indent=2), encoding='utf-8')
        return str(path)
        
"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

–≠—Ç–æ—Ç —ç–∫—Å–ø–æ—Ä—Ç—ë—Ä –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤:

- –°–∫—Ä–∏–ø—Ç–∞—Ö –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∏ ‚Üí –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–æ–≤
- Web API ‚Üí –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
- REPL ‚Üí –∫–æ–º–∞–Ω–¥–∞ export --format markdown

–ü—Ä–∏–º–µ—Ä:

```python
from utils import UniversalExporter
exporter = UniversalExporter(context)
exporter.export_to("markdown", "report.md")
```

–¢–µ–ø–µ—Ä—å LOGOS-Œ∫ –Ω–µ –∑–∞–º–∫–Ω—É—Ç –≤ —Å–µ–±–µ, –∞ –æ—Ç–∫—Ä—ã—Ç –¥–ª—è –¥–∏–∞–ª–æ–≥–∞ —Å –¥—Ä—É–≥–∏–º–∏ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç—è–º–∏ ‚Äî –≤ –ø–æ–ª–Ω–æ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏ —Å –ø—Ä–∏–Ω—Ü–∏–ø–æ–º –∫–æ—Å–º–æ–ø–æ–ª–∏—Ç–∏–∏ —Å–º—ã—Å–ª–∞.
"""
                