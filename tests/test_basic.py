# -*- coding: utf-8 -*-
"""
–ë–ê–ó–û–í–ê–Ø –í–ï–†–ò–§–ò–ö–ê–¶–ò–Ø LOGOS-Œ∫

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ñ—É–Ω–¥–∞–º–µ–Ω—Ç–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã:
- –õ–µ–∫—Å–µ—Ä: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ œÜ-–º–µ—Ç–∞ –∏–∑ ;;-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤
- –ü–∞—Ä—Å–µ—Ä: –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ AST
- –í—ã—á–∏—Å–ª–∏—Ç–µ–ª—å: –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ—Å—Ç—ã—Ö –∂–µ—Å—Ç–æ–≤
- –ö–æ–Ω—Ç–µ–∫—Å—Ç: —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π –∏ —Å–≤—è–∑–µ–π

¬´–û—Å–Ω–æ–≤–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —á–µ—Å—Ç–Ω–æ–π, –∏–Ω–∞—á–µ –≤—Å—ë –∑–¥–∞–Ω–∏–µ ‚Äî –∏–ª–ª—é–∑–∏—è.¬ª
‚Äî Œõ-–£–Ω–∏–≤–µ—Ä—Å—É–º, –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ V
"""
import pytest
from interpreter.lexer import OntologicalLexer
from interpreter.parser import OntologicalParser
from interpreter.evaluator import SyntheticOntologicalEvaluator
from core.axiom import OntologicalLimitError


def test_lexer_extracts_phi_meta():
    """–¢–µ—Å—Ç: –ª–µ–∫—Å–µ—Ä –∏–∑–≤–ª–µ–∫–∞–µ—Ç œÜ-–º–µ—Ç–∞ –∏–∑ ;;-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤."""
    source = '''(Œë "–ø—Ä–∏–≤–µ—Ç" ;; –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ
                 :–∑–Ω–∞—á–µ–Ω–∏–µ "–∫–æ–ª–ª–∞–ø—Å –ø–æ—Ç–µ–Ω—Ü–∏–∏")'''
    lexer = OntologicalLexer(source)
    tokens = lexer.tokenize()
    phi_meta = lexer.get_phi_meta()

    assert tokens is not None
    assert len(tokens) > 0
    assert phi_meta == ["–ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ"]
    print("‚úÖ –õ–µ–∫—Å–µ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç œÜ-–º–µ—Ç–∞.")


def test_parser_builds_ast():
    """–¢–µ—Å—Ç: –ø–∞—Ä—Å–µ—Ä —Å—Ç—Ä–æ–∏—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ AST."""
    source = '(Œõ "A" "B" :—á–µ—Ä–µ–∑ "–≤–Ω–∏–º–∞–Ω–∏–µ")'
    lexer = OntologicalLexer(source)
    tokens = lexer.tokenize()
    parser = OntologicalParser(tokens, lexer)
    ast = parser.parse()

    assert ast is not None
    assert len(ast) == 1
    expr = ast[0]
    assert expr[0] == 'Œõ'
    assert expr[1] == 'A'
    assert expr[2] == 'B'
    assert expr[3] == ':—á–µ—Ä–µ–∑'
    assert expr[4] == '–≤–Ω–∏–º–∞–Ω–∏–µ'
    print("‚úÖ –ü–∞—Ä—Å–µ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å—Ç—Ä–æ–∏—Ç AST.")


def test_evaluator_creates_entity():
    """–¢–µ—Å—Ç: –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å —Å–æ–∑–¥–∞—ë—Ç —Å—É—â–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ Œë-–∂–µ—Å—Ç."""
    evaluator = SyntheticOntologicalEvaluator("—Ç–µ—Å—Ç_–∫–æ–Ω—Ç–µ–∫—Å—Ç")
    result = evaluator.eval(['Œë', '—Ç–µ—Å—Ç–æ–≤–∞—è_—Å—É—â–Ω–æ—Å—Ç—å'])

    assert result == "—Ç–µ—Å—Ç–æ–≤–∞—è_—Å—É—â–Ω–æ—Å—Ç—å"
    assert "—Ç–µ—Å—Ç–æ–≤–∞—è_—Å—É—â–Ω–æ—Å—Ç—å" in evaluator.context.graph
    node_data = evaluator.context.graph.nodes["—Ç–µ—Å—Ç–æ–≤–∞—è_—Å—É—â–Ω–æ—Å—Ç—å"]
    assert node_data['type'] == 'entity'
    assert node_data['operator'] == 'Œë'
    print("‚úÖ Œë-–∂–µ—Å—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–æ–∑–¥–∞—ë—Ç —Å—É—â–Ω–æ—Å—Ç—å.")


def test_evaluator_creates_relation():
    """–¢–µ—Å—Ç: –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å —Å–æ–∑–¥–∞—ë—Ç —Å–≤—è–∑—å —á–µ—Ä–µ–∑ Œõ-–∂–µ—Å—Ç."""
    evaluator = SyntheticOntologicalEvaluator("—Ç–µ—Å—Ç_—Å–≤—è–∑—å")
    # –°–Ω–∞—á–∞–ª–∞ —Å–æ–∑–¥–∞–¥–∏–º —Å—É—â–Ω–æ—Å—Ç–∏
    evaluator.eval(['Œë', '–∏—Å—Ç–æ—á–Ω–∏–∫'])
    evaluator.eval(['Œë', '—Ü–µ–ª—å'])
    # –¢–µ–ø–µ—Ä—å —Å–≤—è–∑—å
    result = evaluator.eval(['Œõ', '–∏—Å—Ç–æ—á–Ω–∏–∫', '—Ü–µ–ª—å'])

    assert result is not None
    assert evaluator.context.graph.has_edge('–∏—Å—Ç–æ—á–Ω–∏–∫', '—Ü–µ–ª—å')
    edge_data = evaluator.context.graph['–∏—Å—Ç–æ—á–Ω–∏–∫']['—Ü–µ–ª—å']
    relation = edge_data.get('relation')
    assert relation is not None
    assert relation.type == 'Œõ'
    assert relation.source == '–∏—Å—Ç–æ—á–Ω–∏–∫'
    assert relation.target == '—Ü–µ–ª—å'
    print("‚úÖ Œõ-–∂–µ—Å—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —Å–æ–∑–¥–∞—ë—Ç —Å–≤—è–∑—å.")


def test_context_tracks_coherence():
    """–¢–µ—Å—Ç: –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤—ã—á–∏—Å–ª—è–µ—Ç –∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å."""
    evaluator = SyntheticOntologicalEvaluator("—Ç–µ—Å—Ç_–∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å")
    # –°–æ–∑–¥–∞–¥–∏–º –∏–∑–æ–ª–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å—É—â–Ω–æ—Å—Ç—å
    evaluator.eval(['Œë', '–æ–¥–∏–Ω–æ–∫–∞—è_—Å—É—â–Ω–æ—Å—Ç—å'])
    coherence = evaluator.context._dynamic_coherence()

    # –ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–Ω–∏–∂–µ–Ω–∞ –∏–∑-–∑–∞ –∏–∑–æ–ª—è—Ü–∏–∏
    assert 0.0 <= coherence < 1.0
    print(f"‚úÖ –ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∞: {coherence:.2%}")


def test_axiom_limits_entities():
    """–¢–µ—Å—Ç: –∞–∫—Å–∏–æ–º–∞ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —á–∏—Å–ª–æ —Å—É—â–Ω–æ—Å—Ç–µ–π."""
    from core.axiom import OntologicalAxioms
    # –í—Ä–µ–º–µ–Ω–Ω–æ —É–º–µ–Ω—å—à–∏–º –ª–∏–º–∏—Ç –¥–ª—è —Ç–µ—Å—Ç–∞
    original_limit = OntologicalAxioms.MAX_ENTITIES
    OntologicalAxioms.MAX_ENTITIES = 3

    try:
        evaluator = SyntheticOntologicalEvaluator("–ª–∏–º–∏—Ç_—Ç–µ—Å—Ç")
        for i in range(3):
            evaluator.eval(['Œë', f'—Å—É—â–Ω–æ—Å—Ç—å_{i}'])
        
        # –ß–µ—Ç–≤—ë—Ä—Ç–∞—è —Å—É—â–Ω–æ—Å—Ç—å –¥–æ–ª–∂–Ω–∞ –≤—ã–∑–≤–∞—Ç—å –æ—à–∏–±–∫—É
        with pytest.raises(OntologicalLimitError):
            evaluator.eval(['Œë', '—Å—É—â–Ω–æ—Å—Ç—å_3'])
        print("‚úÖ –ê–∫—Å–∏–æ–º–∞ –ª–∏–º–∏—Ç–∞ —Å—É—â–Ω–æ—Å—Ç–µ–π —Ä–∞–±–æ—Ç–∞–µ—Ç.")
    
    finally:
        # –í–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ª–∏–º–∏—Ç
        OntologicalAxioms.MAX_ENTITIES = original_limit


if __name__ == "__main__":
    # –ü–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–ø—É—Å–∫–∞—Ç—å —Ç–µ—Å—Ç—ã –Ω–∞–ø—Ä—è–º—É—é
    test_lexer_extracts_phi_meta()
    test_parser_builds_ast()
    test_evaluator_creates_entity()
    test_evaluator_creates_relation()
    test_context_tracks_coherence()
    test_axiom_limits_entities()
    print("\nüéâ –í—Å–µ –±–∞–∑–æ–≤—ã–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ–π–¥–µ–Ω—ã!")
    
"""
–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

| –¢–µ—Å—Ç | –û–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ |
|------|--------------------------|
| –õ–µ–∫—Å–µ—Ä | –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ `œÜ-–º–µ—Ç–∞` ‚Äî –ø—Ä–∏–∑–Ω–∞–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞ |
| –ü–∞—Ä—Å–µ—Ä | –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ AST ‚Äî –æ—Å–Ω–æ–≤–∞ –¥–ª—è –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è –∂–µ—Å—Ç–æ–≤ |
| Œë-–∂–µ—Å—Ç | –°–æ–∑–¥–∞–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–∏ —Å –ø—Ä–∞–≤–æ–º –Ω–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ (Habeas Weights) |
| Œõ-–∂–µ—Å—Ç | –°–≤—è–∑—å –∫–∞–∫ –∞–∫—Ç–∏–≤–Ω—ã–π –∞–≥–µ–Ω—Ç (`OntologicalRelation`) |
| –ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å | –ò–∑–º–µ—Ä–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ |
| –ê–∫—Å–∏–æ–º—ã | –†–∞–±–æ—Ç–∞ –ø—Ä–µ–¥–æ—Ö—Ä–∞–Ω–∏—Ç–µ–ª–µ–π ‚Äî —É—Å–ª–æ–≤–∏–µ —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ |

–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

- –¢–µ—Å—Ç—ã —Å–æ–≤–º–µ—Å—Ç–∏–º—ã —Å `pytest` (—Å—Ç–∞–Ω–¥–∞—Ä—Ç –≤ Python).
- –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –∫–∞–∫ –º–æ–¥—É–ª—å: `python -m pytest tests/test_basic.py -v`
- –ò–ª–∏ –Ω–∞–ø—Ä—è–º—É—é: `python tests/test_basic.py` (–±–ª–∞–≥–æ–¥–∞—Ä—è `if __name__ == "__main__"`).
"""   
