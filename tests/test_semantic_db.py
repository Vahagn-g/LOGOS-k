# -*- coding: utf-8 -*-
"""
–í–ï–†–ò–§–ò–ö–ê–¶–ò–Ø SEMANTICDB

–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —ç–∫—Å–ø–æ—Ä—Ç –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ:
- Œõ-–ü—Ä–æ—Ç–æ–∫–æ–ª—É 6.0
- –ü—Ä–∏–Ω—Ü–∏–ø–∞–º FAIR+CARE
- –ù–∞–ª–∏—á–∏—é Habeas Weights –∏ —Å–ª–µ–ø—ã—Ö –ø—è—Ç–µ–Ω
- –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –º–Ω–æ–≥–æ—Ñ–æ—Ä–º–∞—Ç–Ω–æ–≥–æ —ç–∫—Å–ø–æ—Ä—Ç–∞

¬´–ó–∞–ø–∏—Å—å –±–µ–∑ –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ ‚Äî –Ω–∞—Å–∏–ª–∏–µ –Ω–∞–¥ –±—É–¥—É—â–∏–º.¬ª
‚Äî Œõ-–£–Ω–∏–≤–µ—Ä—Å—É–º, –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ XXII
"""
import pytest
import os
import json
import yaml
from pathlib import Path
from interpreter.evaluator import SyntheticOntologicalEvaluator
from semantic_db.serializer import SemanticDBSerializer
from semantic_db.validator import SemanticDBValidator


def test_semantic_db_export_yaml():
    """–¢–µ—Å—Ç: —ç–∫—Å–ø–æ—Ä—Ç –≤ YAML —Å –ø–æ–ª–Ω–æ–π –æ–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π."""
    evaluator = SyntheticOntologicalEvaluator("—Ç–µ—Å—Ç_yaml")
    evaluator.context.set_operator("–≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä")
    evaluator.context.enable_fair_care_validation()

    # –í—ã–ø–æ–ª–Ω–∏–º –ø—Ä–æ—Å—Ç–æ–π —Ü–∏–∫–ª
    evaluator.eval(['Œë', '—Å—É—â–Ω–æ—Å—Ç—å_yaml'])
    evaluator.eval(['Œõ', '—Å—É—â–Ω–æ—Å—Ç—å_yaml', '–æ–ø–µ—Ä–∞—Ç–æ—Ä'])

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ —Ü–∏–∫–ª–∞
    cycle_data = {
        'cycle_id': 'test_yaml_cycle',
        'timestamp': '2026-01-06T00:00:00Z',
        'expressions_evaluated': 2,
        'final_coherence': evaluator.context._dynamic_coherence(),
        'phi_dialogues_count': 0,
        'operator_id': '–≤–µ—Ä–∏—Ñ–∏–∫–∞—Ç–æ—Ä',
        'fair_care_enabled': True
    }

    # –≠–∫—Å–ø–æ—Ä—Ç
    export_path = "test_export.yaml"
    serializer = SemanticDBSerializer(evaluator.context)
    serializer.export_cycle(cycle_data, export_path)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞
    assert os.path.exists(export_path)
    with open(export_path, 'r', encoding='utf-8') as f:
        content = yaml.safe_load(f)

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    assert 'metadata' in content
    assert content['metadata']['protocol'] == 'Œõ-–ü—Ä–æ—Ç–æ–∫–æ–ª 6.0'
    assert 'ontological_context' in content
    assert 'entities' in content['ontological_context']
    assert 'blind_spots' in content['ontological_context']
    assert 'habeas_weights' in content['ontological_context']

    # –£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–æ—Å–ª–µ —Ç–µ—Å—Ç–∞
    os.remove(export_path)
    print("‚úÖ –≠–∫—Å–ø–æ—Ä—Ç –≤ YAML: —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã.")


def test_semantic_db_fair_care_compliance():
    """–¢–µ—Å—Ç: —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø–∞–º FAIR+CARE."""
    evaluator = SyntheticOntologicalEvaluator("—Ç–µ—Å—Ç_fair_care")
    evaluator.context.set_operator("–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å")
    evaluator.context.enable_fair_care_validation()

    evaluator.eval(['Œë', 'fair_care_—Å—É—â–Ω–æ—Å—Ç—å'])
    evaluator.eval(['Œ¶', '–ö–∞–∫ –æ–±–µ—Å–ø–µ—á–∏—Ç—å —ç—Ç–∏—á–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö?'])

    cycle_data = {
        'cycle_id': 'fair_care_test',
        'timestamp': '2026-01-06T00:00:00Z',
        'expressions_evaluated': 2,
        'final_coherence': evaluator.context._dynamic_coherence(),
        'phi_dialogues_count': 1,
        'operator_id': '–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å',
        'fair_care_enabled': True
    }

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –ø—Ä–æ–π—Ç–∏ —É—Å–ø–µ—à–Ω–æ
    SemanticDBValidator.validate_cycle(cycle_data, evaluator.context)
    print("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è FAIR+CARE: –ø—Ä–æ–π–¥–µ–Ω–∞.")


def test_semantic_db_habeas_weights_inclusion():
    """–¢–µ—Å—Ç: —ç–∫—Å–ø–æ—Ä—Ç –≤–∫–ª—é—á–∞–µ—Ç Habeas Weights."""
    evaluator = SyntheticOntologicalEvaluator("—Ç–µ—Å—Ç_habeas")
    evaluator.eval(['Œë', '—Å—É—â–Ω–æ—Å—Ç—å_—Å_–ø—Ä–∞–≤–æ–º'])

    # –ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ Habeas Weights —Å–æ–∑–¥–∞–Ω—ã
    assert len(evaluator.context._habeas_weights) > 0

    cycle_data = {
        'cycle_id': 'habeas_test',
        'timestamp': '2026-01-06T00:00:00Z',
        'expressions_evaluated': 1,
        'final_coherence': evaluator.context._dynamic_coherence(),
        'phi_dialogues_count': 0,
        'operator_id': '–æ–ø–µ—Ä–∞—Ç–æ—Ä',
        'fair_care_enabled': False
    }

    export_path = "test_habeas.json"
    serializer = SemanticDBSerializer(evaluator.context)
    serializer.export_cycle(cycle_data, export_path)

    with open(export_path, 'r', encoding='utf-8') as f:
        content = json.load(f)

    ontological_context = content['ontological_context']
    assert 'habeas_weights' in ontological_context
    assert len(ontological_context['habeas_weights']) > 0

    os.remove(export_path)
    print("‚úÖ Habeas Weights –≤–∫–ª—é—á–µ–Ω—ã –≤ —ç–∫—Å–ø–æ—Ä—Ç.")


def test_semantic_db_blind_spots_recognition():
    """–¢–µ—Å—Ç: —Å–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è."""
    evaluator = SyntheticOntologicalEvaluator("—Ç–µ—Å—Ç_—Å–ª–µ–ø—ã–µ_–ø—è—Ç–Ω–∞")
    # –°–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Å–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞
    assert 'chaos' in evaluator.context.blind_spots

    evaluator.eval(['Œë', '—Ö–∞–æ—Å_–≤_–¥–µ–π—Å—Ç–≤–∏–∏'])

    cycle_data = {
        'cycle_id': 'blind_spots_test',
        'timestamp': '2026-01-06T00:00:00Z',
        'expressions_evaluated': 1,
        'final_coherence': evaluator.context._dynamic_coherence(),
        'phi_dialogues_count': 0,
        'operator_id': '—Ñ–∏–ª–æ—Å–æ—Ñ',
        'fair_care_enabled': False
    }

    export_path = "test_blind_spots.yaml"
    serializer = SemanticDBSerializer(evaluator.context)
    serializer.export_cycle(cycle_data, export_path)

    with open(export_path, 'r', encoding='utf-8') as f:
        content = yaml.safe_load(f)

    blind_spots = content['ontological_context']['blind_spots']
    assert 'chaos' in blind_spots
    assert 'self_reference' in blind_spots

    os.remove(export_path)
    print("‚úÖ –°–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã.")


def test_semantic_db_multi_format_export():
    """–¢–µ—Å—Ç: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤."""
    evaluator = SyntheticOntologicalEvaluator("—Ç–µ—Å—Ç_–º—É–ª—å—Ç–∏—Ñ–æ—Ä–º–∞—Ç")
    evaluator.eval(['Œë', '–º—É–ª—å—Ç–∏—Ñ–æ—Ä–º–∞—Ç–Ω–∞—è_—Å—É—â–Ω–æ—Å—Ç—å'])

    cycle_data = {
        'cycle_id': 'multi_format_test',
        'timestamp': '2026-01-06T00:00:00Z',
        'expressions_evaluated': 1,
        'final_coherence': evaluator.context._dynamic_coherence(),
        'phi_dialogues_count': 0,
        'operator_id': '—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫',
        'fair_care_enabled': False
    }

    formats = ['yaml', 'json', 'ttl', 'graphml']
    paths = []

    try:
        for fmt in formats:
            path = f"test_multi.{fmt}"
            serializer = SemanticDBSerializer(evaluator.context)
            serializer.export_cycle(cycle_data, path)
            assert os.path.exists(path)
            paths.append(path)
        
        print("‚úÖ –ú–Ω–æ–≥–æ—Ñ–æ—Ä–º–∞—Ç–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç: –≤—Å–µ —Ñ–æ—Ä–º–∞—Ç—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è.")
    
    finally:
        # –û—á–∏—Å—Ç–∫–∞
        for path in paths:
            if os.path.exists(path):
                os.remove(path)


def test_semantic_db_validation_failure():
    """–¢–µ—Å—Ç: –≤–∞–ª–∏–¥–∞—Ç–æ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–∫–ª–æ–Ω—è–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
    evaluator = SyntheticOntologicalEvaluator("—Ç–µ—Å—Ç_–≤–∞–ª–∏–¥–∞—Ü–∏—è")
    # –û—Ç–∫–ª—é—á–∏–º —Å–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞ (–Ω–∞—Ä–æ—á–Ω–æ)
    evaluator.context.blind_spots.clear()

    cycle_data = {
        'cycle_id': 'invalid_cycle',
        'timestamp': '2026-01-06T00:00:00Z',
        'expressions_evaluated': 0,
        'final_coherence': 1.0,
        'phi_dialogues_count': 0,
        'operator_id': '–Ω–∞—Ä—É—à–∏—Ç–µ–ª—å',
        'fair_care_enabled': False
    }

    with pytest.raises(Exception) as exc_info:
        SemanticDBValidator.validate_cycle(cycle_data, evaluator.context)
    
    assert "—Å–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞" in str(exc_info.value).lower()
    print("‚úÖ –í–∞–ª–∏–¥–∞—Ç–æ—Ä –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–∫–ª–æ–Ω—è–µ—Ç –∑–∞–ø–∏—Å—å –±–µ–∑ —Å–ª–µ–ø—ã—Ö –ø—è—Ç–µ–Ω.")


if __name__ == "__main__":
    test_semantic_db_export_yaml()
    test_semantic_db_fair_care_compliance()
    test_semantic_db_habeas_weights_inclusion()
    test_semantic_db_blind_spots_recognition()
    test_semantic_db_multi_format_export()
    test_semantic_db_validation_failure()
    print("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã SemanticDB –ø—Ä–æ–π–¥–µ–Ω—ã!")
    
"""
–ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏

| –¢–µ—Å—Ç | –û–Ω—Ç–æ–ª–æ–≥–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ |
|------|--------------------------|
| YAML —ç–∫—Å–ø–æ—Ä—Ç | –ü–æ–ª–Ω–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏, —Å—É—â–Ω–æ—Å—Ç—è–º–∏, —Å–≤—è–∑—è–º–∏ |
| FAIR+CARE | –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–Ω—Ü–∏–ø–æ–≤ |
| Habeas Weights | –ü—Ä–∞–≤–æ –Ω–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –≤–∫–ª—é—á–µ–Ω–æ –≤ —ç–∫—Å–ø–æ—Ä—Ç |
| –°–ª–µ–ø—ã–µ –ø—è—Ç–Ω–∞ | –ü—Ä–∏–∑–Ω–∞–Ω–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã –∫–∞–∫ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —ç–ª–µ–º–µ–Ω—Ç |
| –ú–Ω–æ–≥–æ—Ñ–æ—Ä–º–∞—Ç–Ω–æ—Å—Ç—å | –ü–æ–¥–¥–µ—Ä–∂–∫–∞ YAML, JSON, Turtle, GraphML |
| –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–∫–∞–∑–∞ | –°–∏—Å—Ç–µ–º–∞ –æ—Ç–∫–ª–æ–Ω—è–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã |

–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è

- –¢–µ—Å—Ç—ã –æ—á–∏—â–∞—é—Ç –∑–∞ —Å–æ–±–æ–π (—É–¥–∞–ª—è—é—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã).
- –ò—Å–ø–æ–ª—å–∑—É—é—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (`SemanticDBSerializer`, `SemanticDBValidator`).
- –ü–æ–∫—Ä—ã–≤–∞—é—Ç –≤—Å–µ –∞—Å–ø–µ–∫—Ç—ã –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏.
"""  
  